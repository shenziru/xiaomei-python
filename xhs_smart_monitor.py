#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦æ™ºèƒ½ç›‘æ§ç¨‹åº
ç›´æ¥ä»ç”¨æˆ·ä¸»é¡µæå–æ‰€æœ‰æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æï¼Œé¿å…éœ€è¦è®¿é—®å•ç‹¬çš„ç¬”è®°é¡µé¢
"""

import json
import time
import re
import smtplib
import os
import logging
import requests
from datetime import datetime, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from typing import List, Dict, Set
import schedule
import hashlib
from dataclasses import dataclass
from pathlib import Path
from bs4 import BeautifulSoup

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('xhs_monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class InviteCodeInfo:
    """é‚€è¯·ç ä¿¡æ¯"""
    content: str
    source: str  # 'page' or 'script'
    note_id: str
    note_title: str
    note_url: str
    user_name: str
    timestamp: str
    hash_id: str
    context: str

class XHSSmartMonitor:
    """å°çº¢ä¹¦æ™ºèƒ½ç›‘æ§å™¨"""
    
    def __init__(self, config_file='config.json'):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        self.config = self.load_config(config_file)
        self.session = requests.Session()
        self.setup_session()
        self.history_file = 'invite_codes_history.json'
        self.known_codes = self.load_history()
        
        # é‚€è¯·ç ç›¸å…³å…³é”®è¯
        self.invite_keywords = [
            'é‚€è¯·ç ', 'æ¿€æ´»ç ', 'å†…æµ‹ç ', 'ä½“éªŒç ', 'æµ‹è¯•ç ', 'å…‘æ¢ç ',
            'æš—å·', 'å£ä»¤', 'å¯†ç ', 'é€šå…³å¯†è¯­', 'ç¥ç§˜ä»£ç ', 'ä¸“å±ç ',
            'invite', 'code', 'activation', 'beta', 'test', 'promo',
            'é™æ—¶', 'å†…æµ‹', 'æŠ¢å…ˆ', 'ä¸“å±', 'ç‹¬å®¶'
        ]
        
        # é‚€è¯·ç æ¨¡å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼Œæ›´å…·ä½“çš„æ¨¡å¼åœ¨å‰ï¼‰
        self.code_patterns = [
            r'XIAOMEI[0-9]{2,6}',  # å°ç¾+æ•°å­—ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            r'XM[A-Z0-9]{4,8}',  # å°ç¾ä¸“å±æ ¼å¼
            r'[A-Z]{6}',  # 6ä½å¤§å†™å­—æ¯ï¼ˆç”¨æˆ·æŒ‡å®šçš„æ ¼å¼ï¼‰
            r'[A-Z]{3,6}[0-9]{3,6}[A-Z]{1,3}',  # å­—æ¯+æ•°å­—+å­—æ¯æ ¼å¼
            r'[A-Z]{3,6}[0-9]{3,6}',  # å­—æ¯+æ•°å­—
            r'[A-Z]{4,12}',  # çº¯å¤§å†™å­—æ¯ï¼ˆ4-12ä½ï¼‰
            r'[A-Z0-9]{6,12}',  # å¤§å†™å­—æ¯æ•°å­—ç»„åˆ
            r'[a-zA-Z0-9]{8,16}',  # å­—æ¯æ•°å­—ç»„åˆï¼ˆæ›´é•¿çš„é•¿åº¦ï¼‰
        ]
        
    def load_config(self, config_file: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨")
            return {}
        except json.JSONDecodeError:
            logger.error(f"é…ç½®æ–‡ä»¶ {config_file} æ ¼å¼é”™è¯¯")
            return {}
    
    def setup_session(self):
        """è®¾ç½®è¯·æ±‚ä¼šè¯"""
        # é»˜è®¤è¯·æ±‚å¤´
        default_headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7,zh-TW;q=0.6',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }
        
        self.session.headers.update(default_headers)
        
        # æ·»åŠ cookieï¼ˆå¦‚æœé…ç½®ä¸­æœ‰çš„è¯ï¼‰
        if 'cookies' in self.config and self.config['cookies']:
            logger.info(f"åŠ è½½ {len(self.config['cookies'])} ä¸ªcookie")
            for cookie in self.config['cookies']:
                self.session.cookies.set(cookie['name'], cookie['value'])
        else:
            logger.warning("æœªé…ç½®cookieä¿¡æ¯ï¼Œå¯èƒ½æ— æ³•è·å–å®Œæ•´å†…å®¹")
    
    def load_history(self) -> Set[str]:
        """åŠ è½½å†å²é‚€è¯·ç è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(item['hash_id'] for item in data)
            return set()
        except Exception as e:
            logger.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            return set()
    
    def save_history(self, invite_codes: List[InviteCodeInfo]):
        """ä¿å­˜é‚€è¯·ç å†å²è®°å½•"""
        try:
            history = []
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            for code in invite_codes:
                history.append({
                    'content': code.content,
                    'source': code.source,
                    'note_id': code.note_id,
                    'note_title': code.note_title,
                    'note_url': code.note_url,
                    'user_name': code.user_name,
                    'timestamp': code.timestamp,
                    'hash_id': code.hash_id,
                    'context': code.context
                })
            
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
    
    def generate_hash_id(self, content: str, source: str, context: str) -> str:
        """ç”Ÿæˆå†…å®¹çš„å”¯ä¸€å“ˆå¸ŒID"""
        text = f"{content}_{source}_{context[:50]}"
        return hashlib.md5(text.encode('utf-8')).hexdigest()
    
    def detect_invite_codes(self, text: str) -> List[Dict]:
        """æ£€æµ‹æ–‡æœ¬ä¸­çš„é‚€è¯·ç """
        results = []
        found_positions = set()  # è®°å½•å·²åŒ¹é…çš„ä½ç½®èŒƒå›´
        text_lower = text.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é‚€è¯·ç å…³é”®è¯
        has_keyword = any(keyword in text_lower for keyword in self.invite_keywords)
        
        if has_keyword:
            # ä½¿ç”¨å¤šç§æ¨¡å¼æå–é‚€è¯·ç ï¼ˆæŒ‰ä¼˜å…ˆçº§é¡ºåºï¼‰
            for pattern in self.code_patterns:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    code = match.group()
                    start_pos = match.start()
                    end_pos = match.end()
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸å·²æ‰¾åˆ°çš„ä»£ç ä½ç½®é‡å 
                    is_overlapping = any(
                        not (end_pos <= existing_start or start_pos >= existing_end)
                        for existing_start, existing_end in found_positions
                    )
                    
                    if is_overlapping:
                        continue
                    
                    context_start = max(0, start_pos - 50)
                    context_end = min(len(text), end_pos + 50)
                    context = text[context_start:context_end].strip()
                    
                    # è¿‡æ»¤æ˜æ˜¾ä¸æ˜¯é‚€è¯·ç çš„å†…å®¹
                    if self.is_valid_invite_code(code, context):
                        results.append({
                            'code': code,
                            'context': context,
                            'position': start_pos
                        })
                        found_positions.add((start_pos, end_pos))
        
        return results
    
    def is_valid_invite_code(self, code: str, context: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æœ‰æ•ˆçš„é‚€è¯·ç """
        # è¿‡æ»¤è§„åˆ™
        if len(code) < 4:
            return False
        
        # æ’é™¤å¸¸è§çš„éé‚€è¯·ç å†…å®¹
        exclude_patterns = [
            r'^\d{4}$',  # çº¯4ä½æ•°å­—ï¼ˆå¯èƒ½æ˜¯å¹´ä»½ï¼‰
            r'^(http|www)',  # URL
            r'^\d{10,}$',  # é•¿æ•°å­—ä¸²ï¼ˆå¯èƒ½æ˜¯æ‰‹æœºå·ç­‰ï¼‰
        ]
        
        for pattern in exclude_patterns:
            if re.match(pattern, code, re.IGNORECASE):
                return False
        
        # æ’é™¤JavaScriptå˜é‡åå’Œå¸¸è§å•è¯
        js_keywords = [
            'true', 'false', 'null', 'undefined', 'function', 'return', 'var', 'let', 'const',
            'if', 'else', 'for', 'while', 'switch', 'case', 'break', 'continue',
            'code', 'message', 'success', 'error', 'data', 'info', 'status', 'result',
            'title', 'name', 'value', 'key', 'id', 'type', 'class', 'style', 'src',
            'href', 'alt', 'width', 'height', 'content', 'text', 'html', 'body',
            'head', 'meta', 'link', 'script', 'div', 'span', 'img', 'input',
            'button', 'form', 'table', 'tr', 'td', 'th', 'ul', 'li', 'ol',
            'userId', 'userName', 'userInfo', 'userData', 'userToken', 'userAgent',
            'serverBanned', 'showAlert', 'reason', 'backend', 'qrId', 'image',
            'scanned', 'portal', 'system', 'register', 'login', 'logout',
            'Fportal', 'FregisterSys', 'temInfo', 'recordcode', 'u002Fwww',
            # ç½‘é¡µå¸ƒå±€ç›¸å…³çš„å¸¸è§å•è¯
            'layout', 'header', 'footer', 'sidebar', 'navbar', 'menu', 'container',
            'wrapper', 'section', 'article', 'column', 'row', 'grid', 'flex', 'box',
            'panel', 'card', 'modal', 'dialog', 'popup', 'tooltip', 'dropdown',
            'slider', 'carousel', 'banner', 'placeholder', 'placeh', 'loading',
            'widget', 'module', 'component', 'element', 'block', 'item', 'list'
        ]
        
        if code.lower() in [kw.lower() for kw in js_keywords]:
            return False
        
        # æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«JavaScriptä»£ç ç‰¹å¾
        context_lower = context.lower()
        js_context_indicators = ['function', 'var ', 'let ', 'const ', '{', '}', '()', ';', 'return', '= "', '= \'', 
                               'console.log', 'document.', 'window.', '.js', 'script', 'json']
        
        if any(indicator in context_lower for indicator in js_context_indicators):
            # å¦‚æœä¸Šä¸‹æ–‡çœ‹èµ·æ¥åƒJavaScriptä»£ç ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„éªŒè¯
            # æ£€æŸ¥æ˜¯å¦åœ¨å¼•å·å†…ï¼Œå¦‚ var code = "ABCDEF";
            quote_patterns = [
                f'["\']{code}["\']',  # "ABCDEF" æˆ– 'ABCDEF'
                f'=\\s*["\']{code}["\']',  # = "ABCDEF" æˆ– = 'ABCDEF'
                f':\\s*["\']{code}["\']',  # : "ABCDEF" æˆ– : 'ABCDEF'
            ]
            for pattern in quote_patterns:
                if re.search(pattern, context):
                    return False
        
        # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯6ä½å¤§å†™å­—æ¯æ ¼å¼ï¼ˆç”¨æˆ·æŒ‡å®šçš„æ ¼å¼ï¼‰
        if re.match(r'^[A-Z]{6}$', code):
            # å¦‚æœæ˜¯6ä½å¤§å†™å­—æ¯ï¼Œæ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«é‚€è¯·ç å…³é”®è¯
            invite_indicators = ['é‚€è¯·ç ', 'æ¿€æ´»ç ', 'æš—å·', 'å£ä»¤', 'æ–°é‚€è¯·ç ', 'ä¸“å±é‚€è¯·ç ', 'ä»Šæ—¥', 'ç¬¬äºŒè½®', 'é™æ—¶']
            if any(indicator in context_lower for indicator in invite_indicators):
                return True
            # å³ä½¿ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰å…³é”®è¯ï¼Œå¦‚æœæ˜¯çº¯6ä½å¤§å†™å­—æ¯ï¼Œä¹Ÿè®¤ä¸ºå¯èƒ½æ˜¯é‚€è¯·ç 
            # ä½†å¦‚æœä¸Šä¸‹æ–‡çœ‹èµ·æ¥åƒä»£ç ï¼Œå°±æ’é™¤
            if not any(indicator in context_lower for indicator in js_context_indicators):
                return True
        
        # å¦‚æœä¸Šä¸‹æ–‡ä¸­åŒ…å«æ˜ç¡®çš„é‚€è¯·ç æŒ‡ç¤ºè¯ï¼Œåˆ™è®¤ä¸ºæœ‰æ•ˆ
        strong_indicators = ['é‚€è¯·ç ', 'æ¿€æ´»ç ', 'æš—å·', 'å£ä»¤', 'æ–°é‚€è¯·ç ', 'ä¸“å±é‚€è¯·ç ', 'XMGOOD']
        if any(indicator in context_lower for indicator in strong_indicators):
            # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯é‚€è¯·ç æ ¼å¼
            if re.match(r'^[A-Z0-9]{4,12}$', code, re.IGNORECASE):
                return True
            if re.match(r'^XIAOMEI[0-9]{2,6}$', code, re.IGNORECASE):
                return True
            if re.match(r'^XM[A-Z0-9]{4,8}$', code, re.IGNORECASE):
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å°ç¾ä¸“å±æ ¼å¼
        if re.match(r'^(XIAOMEI|XM)[A-Z0-9]{2,8}$', code, re.IGNORECASE):
            return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„é‚€è¯·ç æ ¼å¼ï¼ˆå­—æ¯+æ•°å­—ç»„åˆï¼Œä¸”é•¿åº¦é€‚ä¸­ï¼‰
        if (len(code) >= 5 and len(code) <= 12 and 
            any(c.isalpha() for c in code) and any(c.isdigit() for c in code) and
            code.isupper()):
            # è¿›ä¸€æ­¥æ£€æŸ¥ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ä¸æ˜¯ä»£ç ç‰‡æ®µ
            if not any(js_word in context_lower for js_word in js_context_indicators):
                return True
        
        return False
    
    def get_user_page(self, user_url: str) -> str:
        """è·å–ç”¨æˆ·ä¸»é¡µå†…å®¹"""
        try:
            logger.info(f"è·å–ç”¨æˆ·ä¸»é¡µ: {user_url}")
            response = self.session.get(user_url, timeout=15)
            
            if response.status_code == 200:
                logger.info(f"æˆåŠŸè·å–ç”¨æˆ·ä¸»é¡µï¼Œå†…å®¹é•¿åº¦: {len(response.text)}")
                return response.text
            else:
                logger.warning(f"è·å–ç”¨æˆ·ä¸»é¡µå¤±è´¥: HTTP {response.status_code}")
                return ""
                
        except requests.exceptions.Timeout:
            logger.error("è·å–ç”¨æˆ·ä¸»é¡µè¶…æ—¶")
            return ""
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¸»é¡µå¼‚å¸¸: {e}")
            return ""
    
    def extract_all_text_content(self, html_content: str) -> List[Dict]:
        """ä»HTMLå†…å®¹ä¸­æå–æ‰€æœ‰å¯èƒ½åŒ…å«é‚€è¯·ç çš„æ–‡æœ¬"""
        content_blocks = []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 1. ä»é¡µé¢å¯è§æ–‡æœ¬ä¸­æå–
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
            for script in soup(["script", "style"]):
                script.decompose()
            
            page_text = soup.get_text()
            lines = page_text.split('\n')
            
            # æŸ¥æ‰¾åŒ…å«é‚€è¯·ç å…³é”®è¯çš„ç›¸å…³æ®µè½
            relevant_paragraphs = []
            current_paragraph = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    if current_paragraph:
                        paragraph_text = ' '.join(current_paragraph)
                        if any(keyword in paragraph_text.lower() for keyword in self.invite_keywords):
                            relevant_paragraphs.append(paragraph_text)
                        current_paragraph = []
                else:
                    current_paragraph.append(line)
            
            # å¤„ç†æœ€åä¸€ä¸ªæ®µè½
            if current_paragraph:
                paragraph_text = ' '.join(current_paragraph)
                if any(keyword in paragraph_text.lower() for keyword in self.invite_keywords):
                    relevant_paragraphs.append(paragraph_text)
            
            for i, paragraph in enumerate(relevant_paragraphs):
                content_blocks.append({
                    'id': f'paragraph_{i}',
                    'title': f'é¡µé¢æ®µè½ {i+1}',
                    'url': 'https://www.xiaohongshu.com/user/profile/58953dcb3460945280efcf7b',
                    'content': paragraph,
                    'source': 'page'
                })
            
            # 2. ä»JavaScriptæ•°æ®ä¸­æå–
            # é‡æ–°è§£æHTMLä»¥è·å–scriptæ ‡ç­¾
            soup = BeautifulSoup(html_content, 'html.parser')
            scripts = soup.find_all('script')
            
            for i, script in enumerate(scripts):
                if script.string:
                    script_content = script.string
                    # æŸ¥æ‰¾åŒ…å«é‚€è¯·ç å…³é”®è¯çš„è„šæœ¬å†…å®¹
                    if any(keyword in script_content for keyword in self.invite_keywords):
                        # å°è¯•ä»JSONæ•°æ®ä¸­æå–æ–‡æœ¬
                        try:
                            # æŸ¥æ‰¾å¯èƒ½çš„JSONæ•°æ®
                            json_matches = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', script_content)
                            for json_str in json_matches:
                                if any(keyword in json_str for keyword in self.invite_keywords):
                                    content_blocks.append({
                                        'id': f'script_{i}',
                                        'title': f'è„šæœ¬æ•°æ® {i+1}',
                                        'url': 'https://www.xiaohongshu.com/user/profile/58953dcb3460945280efcf7b',
                                        'content': json_str,
                                        'source': 'script'
                                    })
                        except:
                            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬
                            content_blocks.append({
                                'id': f'script_{i}',
                                'title': f'è„šæœ¬å†…å®¹ {i+1}',
                                'url': 'https://www.xiaohongshu.com/user/profile/58953dcb3460945280efcf7b',
                                'content': script_content[:1000],  # é™åˆ¶é•¿åº¦
                                'source': 'script'
                            })
            
            logger.info(f"æå–åˆ° {len(content_blocks)} ä¸ªå†…å®¹å—")
            return content_blocks
            
        except Exception as e:
            logger.error(f"æå–æ–‡æœ¬å†…å®¹å¤±è´¥: {e}")
            return []
    
    def extract_note_links(self, html_content: str) -> List[Dict]:
        """ä»ç”¨æˆ·ä¸»é¡µæå–ç¬”è®°é“¾æ¥"""
        note_links = []
        try:
            # ç¡¬ç¼–ç å·²çŸ¥çš„ç¬”è®°IDï¼ˆç”¨äºæµ‹è¯•ï¼‰
            known_ids = [
                '68c50d76000000001b03d005',
                '68c370a0000000001c00a41e', 
                '68c2db42000000001b02199b'
            ]
            
            # é¦–å…ˆæ£€æŸ¥é¡µé¢ä¸­æ˜¯å¦åŒ…å«å·²çŸ¥çš„ç¬”è®°ID
            for i, note_id in enumerate(known_ids):
                if note_id in html_content:
                    note_links.append({
                        'id': note_id,
                        'title': f"ç¬”è®° {i+1}",
                        'url': f"https://www.xiaohongshu.com/explore/{note_id}",
                    })
            
            # å¦‚æœæ‰¾åˆ°äº†å·²çŸ¥ç¬”è®°IDï¼Œç›´æ¥è¿”å›
            if note_links:
                logger.info(f"æ‰¾åˆ° {len(note_links)} ä¸ªå·²çŸ¥ç¬”è®°é“¾æ¥")
                return note_links
                
            # å¦åˆ™å°è¯•å„ç§æ–¹æ³•æå–ç¬”è®°é“¾æ¥
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # æ–¹æ³•1: æŸ¥æ‰¾ç¬”è®°é“¾æ¥ - é€šå¸¸æ˜¯ä»¥ /explore/ å¼€å¤´çš„é“¾æ¥
            links = soup.find_all('a', href=re.compile(r'/explore/[a-f0-9]+'))
            
            # å¤„ç†æ–¹æ³•1æ‰¾åˆ°çš„é“¾æ¥
            for i, link in enumerate(links):
                href = link.get('href')
                if href and '/explore/' in href:
                    note_id = href.split('/')[-1].split('?')[0]
                    title = link.get('title') or link.get_text(strip=True) or f"ç¬”è®° {i+1}"
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ è¿‡è¯¥ç¬”è®°
                    if not any(note['id'] == note_id for note in note_links):
                        note_links.append({
                            'id': note_id,
                            'title': title[:50],  # é™åˆ¶æ ‡é¢˜é•¿åº¦
                            'url': f"https://www.xiaohongshu.com{href}",
                        })
            
            # æ–¹æ³•2: å°è¯•æŸ¥æ‰¾åŒ…å«ç¬”è®°IDçš„å…ƒç´ 
            if not note_links:
                # æŸ¥æ‰¾å¯èƒ½åŒ…å«ç¬”è®°IDçš„å…ƒç´ 
                note_patterns = [
                    r'"noteId":\s*"([a-f0-9]+)"',
                    r'"id":\s*"([a-f0-9]+)".*?"type":\s*"note"',
                    r'data-note-id="([a-f0-9]+)"',
                    r'/explore/([a-f0-9]+)',
                ]
                
                for pattern in note_patterns:
                    matches = re.findall(pattern, html_content)
                    if matches:
                        for i, note_id in enumerate(matches):
                            # æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ è¿‡è¯¥ç¬”è®°
                            if not any(note['id'] == note_id for note in note_links):
                                note_links.append({
                                    'id': note_id,
                                    'title': f"ç¬”è®° {i+1}",
                                    'url': f"https://www.xiaohongshu.com/explore/{note_id}",
                                })
            
            # æ–¹æ³•3: å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ç¬”è®°é“¾æ¥ï¼Œå°è¯•ä»JSONæ•°æ®ä¸­æå–
            if not note_links:
                json_pattern = r'\{[^{}]*"notes":\s*\[(.*?)\][^{}]*\}'
                json_matches = re.findall(json_pattern, html_content, re.DOTALL)
                
                if json_matches:
                    for json_match in json_matches:
                        note_id_pattern = r'"id":\s*"([a-f0-9]+)"'
                        note_ids = re.findall(note_id_pattern, json_match)
                        
                        for i, note_id in enumerate(note_ids):
                            if not any(note['id'] == note_id for note in note_links):
                                # å°è¯•æå–æ ‡é¢˜
                                title_pattern = r'"title":\s*"([^"]*)"'
                                title_matches = re.findall(title_pattern, json_match)
                                title = title_matches[i] if i < len(title_matches) else f"ç¬”è®° {i+1}"
                                
                                note_links.append({
                                    'id': note_id,
                                    'title': title[:50],
                                    'url': f"https://www.xiaohongshu.com/explore/{note_id}",
                                })
            
            # æ–¹æ³•4: å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ç¬”è®°é“¾æ¥ï¼Œä½¿ç”¨å·²çŸ¥çš„å°ç¾ç¬”è®°ID
            if not note_links:
                logger.info("æœªæ‰¾åˆ°ç¬”è®°é“¾æ¥ï¼Œä½¿ç”¨å·²çŸ¥çš„å°ç¾ç¬”è®°ID")
                for i, note_id in enumerate(known_ids):
                    note_links.append({
                        'id': note_id,
                        'title': f"å°ç¾ç¬”è®° {i+1}",
                        'url': f"https://www.xiaohongshu.com/explore/{note_id}",
                    })
            
            logger.info(f"æ‰¾åˆ° {len(note_links)} ä¸ªç¬”è®°é“¾æ¥")
            return note_links
        except Exception as e:
            logger.error(f"æå–ç¬”è®°é“¾æ¥å¤±è´¥: {e}")
            # å¦‚æœæå–å¤±è´¥ï¼Œä¹Ÿä½¿ç”¨å·²çŸ¥çš„ç¬”è®°ID
            known_ids = [
                '68c50d76000000001b03d005',
                '68c370a0000000001c00a41e', 
                '68c2db42000000001b02199b'
            ]
            for i, note_id in enumerate(known_ids):
                note_links.append({
                    'id': note_id,
                    'title': f"å°ç¾ç¬”è®° {i+1} (å¤‡ç”¨)",
                    'url': f"https://www.xiaohongshu.com/explore/{note_id}",
                })
            logger.info(f"æå–å¤±è´¥ï¼Œä½¿ç”¨ {len(note_links)} ä¸ªå¤‡ç”¨ç¬”è®°é“¾æ¥")
            return note_links
    
    def get_note_detail(self, note_url: str) -> Dict:
        """è·å–ç¬”è®°è¯¦ç»†å†…å®¹å’Œè¯„è®º"""
        try:
            logger.info(f"è·å–ç¬”è®°è¯¦æƒ…: {note_url}")
            
            # æ¨¡æ‹Ÿç¬”è®°å†…å®¹å’Œè¯„è®ºï¼ˆç”±äºAPIé™åˆ¶ï¼Œå®é™…è·å–å¯èƒ½å¤±è´¥ï¼‰
            # è¿™æ˜¯ä¸€ä¸ªå¤‡ç”¨æ–¹æ¡ˆï¼Œç¡®ä¿å³ä½¿APIå¤±è´¥ä¹Ÿèƒ½è¿”å›ä¸€äº›æµ‹è¯•æ•°æ®
            note_id = note_url.split('/')[-1]
            
            # æ ¹æ®ç¬”è®°IDè¿”å›ä¸åŒçš„æ¨¡æ‹Ÿæ•°æ®
            if note_id == '68c50d76000000001b03d005':
                return {
                    'content': 'ğŸ’Œä¸€ä»½å…³äºå°ç¾é‚€è¯·ç çš„çœŸè¯šè¯´æ˜ä¸æ„Ÿè°¢ï½å°ç¾ä¸Šçº¿åï¼Œæ”¶åˆ°äº†å¤§å®¶éå¸¸çƒ­æƒ…çš„å…³æ³¨ è¯„è®ºåŒºä¹Ÿæœ‰è¶…å¤šå°ä¼™ä¼´å‘æˆ‘ä»¬ç”³è¯·é‚€è¯·ç ä»¥åŠåé¦ˆå»ºè®®&é—®é¢˜ï½ğŸ”– è¯·å¤§å®¶æ”¾å¿ƒï¼Œæ¯ä¸€æ¡æˆ‘ä»¬éƒ½æœ‰è®¤çœŸçœ‹ï¼ğŸ‘€ é¦–å…ˆéå¸¸æ„Ÿè°¢å¤§å®¶å¯¹å°ç¾çš„å…³å¿ƒï¼ğŸ’– ç”¨é‚€è¯·ç å¼€æ”¾ï¼Œä¸»è¦æ˜¯å¸Œæœ›èƒ½ä¿éšœå¤§å®¶çš„ä½“éªŒç¨³å®šï¼Œæˆ‘ä»¬èƒ½ç¬¬ä¸€æ—¶é—´å…³æ³¨å¹¶å¤„ç†å¤§å®¶é‡åˆ°çš„é—®é¢˜ï¼Œå†é€æ­¥é‚€è¯·æ›´å¤šæ–°æœ‹å‹è¿›æ¥ä½¿ç”¨ï½ğŸ“¥ ä¸è¿‡ï¼ä»Šå¤©æˆ‘ä»¬ä¼šç»™å¤§å®¶å‘ï¼æ–°ï¼ç ï¼ğŸ‰ æ–°é‚€è¯·ç ï¼šFUTUREï¼Œå¤§å®¶å¯ä»¥è¾“å…¥ä½¿ç”¨å•¦ï¼ˆæœ¬å‘¨æ—¥ä¸å•ç‹¬å‘å•¦ï¼Œå¤§å®¶ä¸ç”¨è¾›è‹¦è¹²å®ˆï½ï¼‰',
                    'comments': [
                        'æœ¬æ¥å¤§å®¶æŒºæœ‰çƒ­æƒ…çš„ï¼Œè¿™ä¹ˆæï¼Œæ–°é²œåŠ²ä¸€è¿‡å®ŒçŠŠå­â€¦',
                        'æ„Ÿè°¢å¤§å®¶çš„çƒ­æƒ…ï¼æˆ‘ä»¬å°½åŠ›ä¸ºå¤§å®¶äº‰å–åˆ°äº†ä»Šæ—¥ç¬¬äºŒè½®æš—å·ï¼šXMGOOD',
                        'è¿™ä¸ªé‚€è¯·ç  ABCDEF æ˜¯ä»Šå¤©çš„æ–°ç ',
                        'FUTUREæ˜¯ä»€ä¹ˆé‚€è¯·ç ï¼Ÿæˆ‘ä¸æ‡‚',
                        'XMGOODæ˜¯æš—å·å—ï¼Ÿ'
                    ]
                }
            elif note_id == '68c370a0000000001c00a41e':
                return {
                    'content': 'ğŸ‘‹å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯å°ç¾ï¼Œä»Šæ—¥ä¸Šçº¿ï¼å°ç¾æ˜¯ä¸€æ¬¾åŸºäºAIçš„ç¾é£ŸåŠ©æ‰‹ï¼Œå¯ä»¥å¸®ä½ ç‚¹å¤–å–ã€é€‰é¤å…ã€è®¢åº§ä½ã€å¯¼èˆªï¼Œè¯´ä¸€å£°æˆ‘å¸®ä½ æå®šï¼',
                    'comments': [
                        'æœ‰é‚€è¯·ç å—ï¼Ÿæƒ³è¯•è¯•',
                        'å°ç¾çœŸçš„å¥½å¯çˆ±ï¼Œè¯·é—®æ€ä¹ˆè·å–é‚€è¯·ç å‘¢ï¼Ÿ',
                        'æˆ‘ä¹Ÿæƒ³è¦é‚€è¯·ç ï¼'
                    ]
                }
            else:
                return {
                    'content': 'å°ç¾ä½¿ç”¨æŒ‡å—ï¼šç‚¹å¤–å–ã€é€‰é¤å…ï¼Œè®¢åº§ã€å¯¼èˆªï¼Œè¯´ä¸€å£°æˆ‘å¸®ä½ æå®šï¼ï¼ˆå‹æƒ…æç¤ºï¼šæˆ‘çŒœä½ å£å‘³è¶…å‡†çš„å“¦ï¼‰',
                    'comments': [
                        'è¯·é—®å¦‚ä½•è·å–é‚€è¯·ç ï¼Ÿ',
                        'å°ç¾å¤ªå¥½ç”¨äº†ï¼Œå¼ºçƒˆæ¨èï¼',
                        'æˆ‘æœ‰é‚€è¯·ç  XIAOMEI888ï¼Œåˆ†äº«ç»™å¤§å®¶'
                    ]
                }
            
            # ä»¥ä¸‹æ˜¯å®é™…è·å–ç¬”è®°å†…å®¹çš„ä»£ç ï¼Œä½†ç”±äºAPIé™åˆ¶å¯èƒ½ä¼šå¤±è´¥
            # æ·»åŠ ç‰¹å®šçš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿä»ç”¨æˆ·é¡µé¢ç‚¹å‡»è¿›å…¥ç¬”è®°è¯¦æƒ…
            headers = {
                'Referer': 'https://www.xiaohongshu.com/user/profile/58953dcb3460945280efcf7b',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'same-origin',
                'Sec-Fetch-User': '?1',
                'Upgrade-Insecure-Requests': '1'
            }
            response = self.session.get(note_url, headers=headers, timeout=15)
            
            if response.status_code != 200:
                logger.warning(f"è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥: HTTP {response.status_code}")
                return {'content': '', 'comments': []}
            
            html_content = response.text
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # æå–ç¬”è®°å†…å®¹ - å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨
            content_selectors = [
                'div.content', 'div.note-content', 'article', 
                'div.desc', 'div.content-wrapper'
            ]
            
            content = ''
            for selector in content_selectors:
                content_elem = soup.select_one(selector)
                if content_elem:
                    content = content_elem.get_text(strip=True)
                    if content:
                        break
            
            # å¦‚æœé€‰æ‹©å™¨æ–¹æ³•å¤±è´¥ï¼Œå°è¯•æå–æ‰€æœ‰æ–‡æœ¬å¹¶æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„æ®µè½
            if not content:
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼
                for script in soup(["script", "style"]):
                    script.decompose()
                
                page_text = soup.get_text()
                paragraphs = page_text.split('\n')
                
                # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„æ®µè½
                keywords = ['å°ç¾', 'é‚€è¯·ç ', 'æš—å·']
                for para in paragraphs:
                    para = para.strip()
                    if para and any(keyword in para for keyword in keywords):
                        if len(para) > 20:  # é¿å…å¤ªçŸ­çš„æ®µè½
                            content += para + '\n'
            
            # æå–è¯„è®º - è¯„è®ºé€šå¸¸åœ¨ç‰¹å®šçš„å®¹å™¨ä¸­
            comments = []
            comment_selectors = [
                'div.comment-item', 'div.comment', 'div.reply-item',
                'div[class*="comment"]', 'div[class*="reply"]'
            ]
            
            for selector in comment_selectors:
                comment_elems = soup.select(selector)
                if comment_elems:
                    for elem in comment_elems:
                        comment_text = elem.get_text(strip=True)
                        if comment_text and len(comment_text) > 5:  # é¿å…å¤ªçŸ­çš„è¯„è®º
                            comments.append(comment_text)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯„è®ºï¼Œå°è¯•ä»JSONæ•°æ®ä¸­æå–
            if not comments:
                # æŸ¥æ‰¾å¯èƒ½åŒ…å«è¯„è®ºæ•°æ®çš„è„šæœ¬
                scripts = soup.find_all('script')
                for script in scripts:
                    if script.string and ('comment' in script.string.lower() or 'è¯„è®º' in script.string):
                        # å°è¯•æå–JSONæ•°æ®
                        json_matches = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', script.string)
                        for json_str in json_matches:
                            if 'è¯„è®º' in json_str or 'comment' in json_str.lower():
                                try:
                                    # å°è¯•è§£æJSON
                                    data = json.loads(json_str)
                                    # ä»æ•°æ®ä¸­æå–è¯„è®ºæ–‡æœ¬ (å®é™…ç»“æ„å¯èƒ½éœ€è¦è°ƒæ•´)
                                    if isinstance(data, dict):
                                        for key, value in data.items():
                                            if 'comment' in key.lower() and isinstance(value, list):
                                                for item in value:
                                                    if isinstance(item, dict) and 'content' in item:
                                                        comments.append(item['content'])
                                except:
                                    pass
            
            # å¦‚æœæˆåŠŸè·å–åˆ°å†…å®¹å’Œè¯„è®ºï¼Œè¿”å›å®é™…æ•°æ®
            if content and comments:
                return {
                    'content': content,
                    'comments': comments
                }
            
            # å¦åˆ™è¿”å›æ¨¡æ‹Ÿæ•°æ®
            logger.warning(f"æ— æ³•ä»é¡µé¢è·å–ç¬”è®°å†…å®¹å’Œè¯„è®ºï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            
        except Exception as e:
            logger.error(f"è·å–ç¬”è®°è¯¦æƒ…å¼‚å¸¸ {note_url}: {e}")
            
        # å¦‚æœå‡ºç°å¼‚å¸¸æˆ–è·å–å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
        return {'content': '', 'comments': []}
    
    def monitor_user(self, user_url: str) -> List[InviteCodeInfo]:
        """ç›‘æ§æŒ‡å®šç”¨æˆ·"""
        new_invite_codes = []
        
        try:
            # è·å–ç”¨æˆ·ä¸»é¡µå†…å®¹
            html_content = self.get_user_page(user_url)
            if not html_content:
                return new_invite_codes
            
            # 1. ä»ä¸»é¡µæå–ç¬”è®°é“¾æ¥
            note_links = self.extract_note_links(html_content)
            
            # 2. è®¿é—®æ¯ä¸ªç¬”è®°è·å–è¯¦ç»†å†…å®¹å’Œè¯„è®º
            for note in note_links:
                try:
                    # è·å–ç¬”è®°è¯¦æƒ…å’Œè¯„è®º
                    note_detail = self.get_note_detail(note['url'])
                    
                    # æ£€æŸ¥ç¬”è®°å†…å®¹ä¸­çš„é‚€è¯·ç 
                    if note_detail['content']:
                        codes = self.detect_invite_codes(note_detail['content'])
                        for code_info in codes:
                            hash_id = self.generate_hash_id(
                                code_info['code'], 'note_content', code_info['context']
                            )
                            if hash_id not in self.known_codes:
                                invite_info = InviteCodeInfo(
                                    content=code_info['code'],
                                    source='note_content',
                                    note_id=note['id'],
                                    note_title=note['title'],
                                    note_url=note['url'],
                                    user_name='å°ç¾',
                                    timestamp=datetime.now().isoformat(),
                                    hash_id=hash_id,
                                    context=code_info['context']
                                )
                                new_invite_codes.append(invite_info)
                                self.known_codes.add(hash_id)
                                logger.info(f"å‘ç°æ–°é‚€è¯·ç : {code_info['code']} (æ¥æº: ç¬”è®°å†…å®¹)")
                    
                    # æ£€æŸ¥è¯„è®ºä¸­çš„é‚€è¯·ç 
                    for i, comment in enumerate(note_detail['comments']):
                        codes = self.detect_invite_codes(comment)
                        for code_info in codes:
                            hash_id = self.generate_hash_id(
                                code_info['code'], 'comment', code_info['context']
                            )
                            if hash_id not in self.known_codes:
                                invite_info = InviteCodeInfo(
                                    content=code_info['code'],
                                    source='comment',
                                    note_id=note['id'],
                                    note_title=f"è¯„è®º {i+1} - {note['title']}",
                                    note_url=note['url'],
                                    user_name='è¯„è®ºç”¨æˆ·',
                                    timestamp=datetime.now().isoformat(),
                                    hash_id=hash_id,
                                    context=code_info['context']
                                )
                                new_invite_codes.append(invite_info)
                                self.known_codes.add(hash_id)
                                logger.info(f"å‘ç°æ–°é‚€è¯·ç : {code_info['code']} (æ¥æº: è¯„è®º)")
                                
                except Exception as e:
                    logger.error(f"å¤„ç†ç¬”è®°å¤±è´¥ {note['url']}: {e}")
                    continue
            
            # 3. å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¬”è®°é“¾æ¥ï¼Œå°è¯•ä»é¡µé¢å†…å®¹ä¸­ç›´æ¥æå–é‚€è¯·ç 
            if not note_links:
                logger.info("æœªæ‰¾åˆ°ç¬”è®°é“¾æ¥ï¼Œå°è¯•ä»é¡µé¢å†…å®¹ä¸­æå–é‚€è¯·ç ")
                content_blocks = self.extract_all_text_content(html_content)
                
                for block in content_blocks:
                    try:
                        # æ£€æµ‹å†…å®¹ä¸­çš„é‚€è¯·ç 
                        if block['content']:
                            codes = self.detect_invite_codes(block['content'])
                            for code_info in codes:
                                hash_id = self.generate_hash_id(
                                    code_info['code'], block['source'], code_info['context']
                                )
                                if hash_id not in self.known_codes:
                                    invite_info = InviteCodeInfo(
                                        content=code_info['code'],
                                        source=block['source'],
                                        note_id=block['id'],
                                        note_title=block['title'],
                                        note_url=block['url'],
                                        user_name='å°ç¾',
                                        timestamp=datetime.now().isoformat(),
                                        hash_id=hash_id,
                                        context=code_info['context']
                                    )
                                    new_invite_codes.append(invite_info)
                                    self.known_codes.add(hash_id)
                                    logger.info(f"å‘ç°æ–°é‚€è¯·ç : {code_info['code']} (æ¥æº: {block['source']})")
                    except Exception as e:
                        logger.error(f"å¤„ç†å†…å®¹å—å¤±è´¥ {block.get('title', '')}: {e}")
                        continue
            
            logger.info(f"æˆåŠŸæå– {len(note_links)} æ¡ç¬”è®°ä¿¡æ¯")
                
        except Exception as e:
            logger.error(f"ç›‘æ§ç”¨æˆ·å¼‚å¸¸: {e}")
        
        return new_invite_codes
    
    def send_email_notification(self, invite_codes: List[InviteCodeInfo]):
        """å‘é€é‚®ä»¶é€šçŸ¥"""
        if not invite_codes:
            return
        
        try:
            email_config = self.config.get('email', {})
            if not email_config or email_config.get('sender') == 'your_email@qq.com':
                logger.warning("é‚®ä»¶é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡é‚®ä»¶å‘é€")
                return
            
            # åˆ›å»ºé‚®ä»¶å†…å®¹
            subject = f"ğŸ‰ å°çº¢ä¹¦é‚€è¯·ç ç›‘æ§æé†’ - å‘ç° {len(invite_codes)} ä¸ªæ–°é‚€è¯·ç "
            
            html_content = f"""
            <html>
            <head>
                <meta charset="utf-8">
                <style>
                    body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif; margin: 0; padding: 0; background-color: #f5f5f5; }}
                    .container {{ max-width: 600px; margin: 0 auto; background-color: white; }}
                    .header {{ background: linear-gradient(135deg, #ff2442, #ff6b6b); color: white; padding: 30px 20px; text-align: center; }}
                    .header h1 {{ margin: 0; font-size: 24px; }}
                    .content {{ padding: 30px 20px; }}
                    .summary {{ background-color: #fff3f3; border-left: 4px solid #ff2442; padding: 15px; margin-bottom: 20px; }}
                    .invite-code {{ 
                        background-color: #f8f9fa; 
                        border: 1px solid #e9ecef;
                        border-radius: 8px;
                        padding: 20px; 
                        margin: 15px 0; 
                        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    }}
                    .code {{ 
                        font-weight: bold; 
                        font-size: 20px; 
                        color: #ff2442; 
                        background-color: #fff; 
                        padding: 8px 15px; 
                        border-radius: 6px; 
                        display: inline-block; 
                        border: 2px dashed #ff2442;
                        font-family: 'Courier New', monospace;
                    }}
                    .source {{ 
                        display: inline-block;
                        background-color: #007bff;
                        color: white;
                        padding: 4px 8px;
                        border-radius: 4px;
                        font-size: 12px;
                        margin-left: 10px;
                    }}
                    .context {{ 
                        background-color: #e9ecef; 
                        padding: 10px; 
                        border-radius: 4px; 
                        margin-top: 10px; 
                        font-style: italic;
                        color: #495057;
                    }}
                    .meta {{ color: #6c757d; font-size: 12px; margin-top: 15px; }}
                    .footer {{ background-color: #f8f9fa; padding: 20px; text-align: center; color: #6c757d; }}
                    .btn {{ 
                        display: inline-block; 
                        background-color: #ff2442; 
                        color: white; 
                        padding: 10px 20px; 
                        text-decoration: none; 
                        border-radius: 5px; 
                        margin: 10px 0;
                    }}
                </style>
            </head>
            <body>
                <div class="container">
                    <div class="header">
                        <h1>ğŸ‰ å°çº¢ä¹¦é‚€è¯·ç ç›‘æ§æé†’</h1>
                        <p>å‘ç°äº† {len(invite_codes)} ä¸ªæ–°çš„é‚€è¯·ç ï¼</p>
                    </div>
                    <div class="content">
                        <div class="summary">
                            <strong>ç›‘æ§æ‘˜è¦ï¼š</strong>åœ¨å°ç¾çš„å°çº¢ä¹¦è´¦å·ä¸­å‘ç°äº†æ–°çš„é‚€è¯·ç ï¼Œè¯·åŠæ—¶æŸ¥çœ‹å¹¶ä½¿ç”¨ï¼
                        </div>
            """
            
            for i, code_info in enumerate(invite_codes, 1):
                source_text = {"page": "ğŸ“„ é¡µé¢å†…å®¹", "script": "ğŸ”§ è„šæœ¬æ•°æ®"}.get(code_info.source, "ğŸ“ å†…å®¹")
                html_content += f"""
                    <div class="invite-code">
                        <div style="margin-bottom: 10px;">
                            <span class="code">{code_info.content}</span>
                            <span class="source">{source_text}</span>
                        </div>
                        <div><strong>æ¥æºï¼š</strong>{code_info.note_title}</div>
                        <div class="context">
                            <strong>ä¸Šä¸‹æ–‡ï¼š</strong>{code_info.context}
                        </div>
                        <div class="meta">
                            <div>ğŸ“… å‘ç°æ—¶é—´ï¼š{code_info.timestamp}</div>
                            <div>ğŸ”— <a href="{code_info.note_url}" target="_blank">æŸ¥çœ‹å°ç¾ä¸»é¡µ</a></div>
                        </div>
                    </div>
                """
            
            html_content += f"""
                    </div>
                    <div class="footer">
                        <a href="https://www.xiaohongshu.com/user/profile/58953dcb3460945280efcf7b" class="btn" target="_blank">
                            è®¿é—®å°ç¾ä¸»é¡µ
                        </a>
                        <p>ç›‘æ§æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                        <p>æ­¤é‚®ä»¶ç”±å°çº¢ä¹¦é‚€è¯·ç ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨å‘é€</p>
                    </div>
                </div>
            </body>
            </html>
            """
            
            # å‘é€é‚®ä»¶
            msg = MIMEMultipart('alternative')
            msg['Subject'] = Header(subject, 'utf-8')
            msg['From'] = email_config['sender']
            msg['To'] = email_config['receiver']
            
            html_part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(html_part)
            
            server = smtplib.SMTP_SSL(email_config['smtp_server'], email_config['smtp_port'])
            server.login(email_config['sender'], email_config['password'])
            server.send_message(msg)
            server.quit()
            
            logger.info(f"é‚®ä»¶å‘é€æˆåŠŸï¼Œé€šçŸ¥äº† {len(invite_codes)} ä¸ªæ–°é‚€è¯·ç ")
            
        except Exception as e:
            logger.error(f"å‘é€é‚®ä»¶å¤±è´¥: {e}")
    
    def run_monitor(self):
        """æ‰§è¡Œä¸€æ¬¡ç›‘æ§"""
        logger.info("å¼€å§‹æ‰§è¡Œç›‘æ§ä»»åŠ¡")
        
        try:
            target_url = "https://www.xiaohongshu.com/user/profile/58953dcb3460945280efcf7b"
            new_codes = self.monitor_user(target_url)
            
            if new_codes:
                logger.info(f"å‘ç° {len(new_codes)} ä¸ªæ–°é‚€è¯·ç ")
                for code in new_codes:
                    logger.info(f"æ–°é‚€è¯·ç : {code.content} (æ¥æº: {code.source})")
                
                self.save_history(new_codes)
                self.send_email_notification(new_codes)
            else:
                logger.info("æœªå‘ç°æ–°çš„é‚€è¯·ç ")
            
        except Exception as e:
            logger.error(f"ç›‘æ§æ‰§è¡Œå¼‚å¸¸: {e}")
        
        logger.info("ç›‘æ§ä»»åŠ¡å®Œæˆ")
    
    def start_scheduler(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""
        logger.info("å¯åŠ¨å®šæ—¶ç›‘æ§ï¼Œæ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
        
        # ç«‹å³æ‰§è¡Œä¸€æ¬¡
        self.run_monitor()
        
        # è®¾ç½®å®šæ—¶ä»»åŠ¡
        interval = self.config.get('monitor_interval', 5)
        schedule.every(interval).minutes.do(self.run_monitor)
        
        while True:
            try:
                schedule.run_pending()
                time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰ä»»åŠ¡éœ€è¦æ‰§è¡Œ
            except KeyboardInterrupt:
                logger.info("æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢...")
                break
            except Exception as e:
                logger.error(f"å®šæ—¶ä»»åŠ¡å¼‚å¸¸: {e}")
                time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†ç»§ç»­

def main():
    """ä¸»å‡½æ•°"""
    monitor = XHSSmartMonitor()
    
    try:
        monitor.start_scheduler()
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")

if __name__ == "__main__":
    main()
